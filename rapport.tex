\documentclass[a4paper]{article}

\usepackage[french]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{url}

\title{Rapport ADR : Reconnaissance de documents pour la réalité augmentée}

\author{Gwendal Le Moulec}

\date{\today}

\begin{document}
\maketitle

\begin{abstract}
Your abstract.
\end{abstract}

\section{Introduction}

A l'ère de l'information à grande échelle, la manière de lire de documents n'est plus la même qu'il y a vingt ans. La grande disponibilité des multitudes de sources de données permet à n'importe quel lecteur d'élargir un sujet de lecture, en cherchant lui-même les documents "liés", c'est à dire les documents qui traitent d'au moins une information contenue dans le document initial. Bien souvent, de simples mots-clés couvrent un sujet connexe au sujet principal. Ces mots-clés sont suffisants pour définir un critère de recherche dans une base de données.

Un champ important de recherche en informatique consiste à automatiser ce suivi de liens dans les documents. Les hyperliens que l'on trouve dans les bases de documents comme la fameuse encyclopédie en ligne Wikipédia matérialisent ces connexions de manière simple. Cependant, ce genre d'approche présente quelques faiblesses~: elle ne s'applique qu'au documents numériques et c'est l'auteur du document qui doit définir le lien physique ou au moins préparer le document de manière à ce que la définition du lien soit possible \textit{a posteriori}. Ainsi, un document rédigé dans un format non compatible ne peut définitivement plus être à l'origine de liens.

Cette situation est un peu absurde, puisque ce n'est pas le format du document qui apporte la connaissance, mais bien le contenu du document lui-même. C'est pourquoi on recherche aujourd'hui des méthodes qui permettent d'indexer automatiquement les contenus et bien sûr d'interagir avec des documents indépendamment de leur format, qu'ils soient numériques ou non. Les auteurs des articles présentés dans le présent rapport proposent un mécanisme basé sur la réalité augmentée. La réalité augmentée est un paradigme qui couvre les technologies permettant d'ajouter des données virtuelles dans un monde réel et d'introduire de l'interaction entre les deux \cite{augmented-reality}. Concrètement, le système présenté est constitué de lunettes de réalité augmentée qui permettent d'afficher du contenu virtuel lié au mot fixé par le lecteur. Pour ce faire, le système tente d'abord de reconnaître le document parmi une multitude de références dans une base de données. Ensuite, la reconnaissance d'un mot fixé par le lecteur se fait par mise en relation entre la position du point fixé par le lecteur - détectable grâce à un dispositif de suivi oculaire - et le mot situé à cette position dans la version référencée du document.

Nous présenterons tout d'abord les deux articles proposés afin d'en faire un synthèse. Ils feront ensuite l'objet d'une critique mettant en avant les qualités et les défauts des explications, de la démarche et des résultats présentés.

\section{Présentation des articles}

Les deux articles proposés sont \textit{Wearable Reading Assist System: Augmented Reality Document Combining Document Retrieval and Eye Tracking} (T. Toyama, A. Dengel, W. Suzuki et K. Kise) et \textit{Real-Time Document Image Retrieval for a 10 Million Pages Database with a Memory Efficient and Stability Improved LLAH} (K. Takeda, K. Kise et M. Iwamura). Le premier présente le système général et en particulier la méthode de suivi oculaire, pour la détection des mots fixés successivement par le lecteur. Le deuxième se concentre sur la méthode de reconnaissance de document.

\subsection{Interaction homme-document par suivi oculaire}

Les auteurs du premier article commencent par étudier l'état de l'art de l'interaction sur document par la vision. Il existe des dispositifs adaptés à la lecture sur ordinateur aussi bien que des systèmes portables. Ce sont ces derniers sur lesquelles la méthode proposée se base.

Cette méthode est décomposée en trois modules~:
\begin{description}
	\item[Extraction de document~:] association du document lu avec l'un des documents de la base de données. Le document extrait est appelé image du document.
	\item[Analyse du regard~:] détection des mots-clés fixés successivement.
	\item[Visualisation virtuelle~:] visualisation des données associées au dernier mot-clé fixé.
\end{description}

La figure \ref{fig:system} résume le fonctionnement global du système. L'utilisateur doit porter un dispositif de visualisation composé de lunettes spéciales munies d'un appareil de suivi oculaire sur lesquelles sont montées un petit écran laissant voir le monde réel mais pouvant afficher des données virtuelles. Lorsqu'un document est "présenté" au dispositif, le module d'extraction de documents cherche le document associé. La procédure est expliquée au paragraphe suivant (\ref{subsec:reconnaissance}). Lors de la lecture, l'utilisateur peut fixer des mots. Si ces derniers sont des mots-clés, ils sont stockés dans une pile en attendant que le lecteur porte son regard sur l'écran de réalité augmentée. C'est seulement à ce moment-là que les informations sur le dernier mot-clé fixé sont affichées. En effet, l'affichage de ces données de manière intempestive pourrait gêner l'utilisateur en obstruant son champ de vision.

La détection du regard se fait par projection de rayons infrarouges sur les yeux. Les changements d'angles de réflexion de ces rayons infrarouges permettent de déduire la direction du regard. Ce mécanisme nécessite une calibration pour chaque utilisateur différent.

\begin{figure}[!h]
\centering
\includegraphics[width=\textwidth]{res/systeme_global.png}
\caption{\label{fig:system}Système global.}
\end{figure}

\subsection{Reconnaissance de documents}
\label{subsec:reconnaissance}

Les auteurs du second article proposent une version améliorée d'une technique appelée LLAH (Locally Likely Arrangement Hashing). En effet, cette technique présente deux défauts majeurs~: elle est gourmande en mémoire et son efficacité diminue si la taille de la base de donnée est grande, car il y a plus de chances de rencontrer des documents semblables.

\subsubsection{Fonctionnement de LLAH}
Le fonctionnement de LLAH est le suivant~: au moment du référencement dans la base de données, les points caractéristiques sont extraits. Il s'agit de centroïdes de mots, dont la position varie peu en cas de distorsion. Cette propriété est essentielle pour pouvoir associer efficacement deux documents.

A chaque point caractéristique est associé un vecteur de caractéristiques $V$ tel que~:
\begin{enumerate}
	\item $d = ({m\choose 4} + m)$, où $d$ est la dimension de $V$ et $m$ est un paramètre.
	\item $V = (r_0, ..., r_{{m\choose 4}-1}, q_0, ..., q_{m-1})$, où pour tout $i = 0, ..., {m\choose 4}-1$~:
	
	$r_i = \frac{P(C_{i_1}, C_{i_3}, C_{i_4})}{P(C_{i_1}, C_{i_2}, C_{i_3})}$
	
	Le quadrilatère $C_{i_1}C_{i_2}C_{i_3}C_{i_4}$ étant non-croisé et dont les sommets constituent une combinaison de 4 points parmi les $m$ plus proches voisins du centroïde considéré, lui-même inclus, et $P(A,B,C)$ étant l'aire du triangle $ABC$. Les deux triangles comparés ont donc une arête en commun. Une distorsion provoque une division de l'aire de deux triangles par un même facteur. Le rapport des deux aires est donc invariant par rapport à la distorsion, ce qui explique le choix de cette caractéristique.
\end{enumerate}

\textbf{Remarque personnelle~:} \textit{l'article explique mal la signification des valeurs de $q_0$ à $q_{m-1}$. Il est dit qu'il s'agit des rangs des rapports entre les aires occupées par des mots voisins. La figure \ref{fig:features}, tirée de l'article, montre un exemple pour $m = 6$. Les rapports d'aires semblent triés, mais selon quel critère ? Le tri ne semble pas cohérent avec les rapports apparents. De plus, le sens de comparaison n'est pas spécifié. Pour chaque couple de mot, quelle aire est au numérateur ? Quelle aire est au dénominateur ?}

\begin{figure}[!h]
\centering
\includegraphics[width=0.35\textwidth]{res/features.png}
\caption{\label{fig:features}Calcul du vecteur de caractéristique pour un centroïde.}
\end{figure}

Pour trouver l'image d'un document dans la base de données, on calcule les vecteurs de caractéristiques du document en entrée. L'image correspondante est déterminée par un système de vote~: pour chaque vecteur de caractéristiques, on accorde une voix supplémentaire à tous les documents référencés qui le possèdent également. Le document qui remporte le plus de voix "gagne".

\subsubsection{LLAH amélioré}
La première amélioration proposée est destinée à réduire la consommation en mémoire. Les auteurs proposent de réduire le nombre de points caractéristiques enregistrés car l'algorithme de mise en correspondance, basé sur le vote, n'est pas sensible aux variations du nombre de votants à partir d'un certain seuil. ce seuil est fixé à 200 points caractéristiques au minimum.

Il s'avère aussi que pour des bases de 10 million de pages, les vecteurs de caractéristiques ne sont pas assez discriminants. Pour augmenter le pouvoir de discrimination d'un vecteur, il suffit d'augmenter sa dimension. dans notre cas, une augmentation de la valeur du paramètre $m$ est suffisante. Cependant, augmenter la dimension d'un vecteur augmente aussi le risque d'échec de la comparaison de deux vecteurs qui "devraient être égaux". C'est la raison pour laquelle on supprime également l'information redondante. C'est ainsi que certains attributs de $r_0$ à $r_{{m\choose 4}-1}$ sont éliminés, de façon à ne faire intervenir chaque triangle qu'une seule fois dans tous les calculs.\\
\\

\textbf{Remarque personnelle~:} \textit{Les auteurs justifient ce "filtrage" par le fait qu'étant donnés trois attributs $r_1 = \frac{P_1}{P_2}$, $r_2 = \frac{P_2}{P_3}$ et $r_3 = \frac{P_3}{P_4}$, $r_2$ entretient nécessairement une relation avec $r_1$ et $r_3$. Cependant, cette affirmation n'est pas démontrée rigoureusement. Par exemple, l'un n'est pas une combinaison linéaire des deux autres. Aucun modèle mathématique associé à la distorsion n'est proposé pour démontrer qu'il y a bel et bien redondance d'information.}


\section{Commentaires}

\subsection{Expérimentations de la version améliorée de LLAH}
Deux expériences ont servi à tester les performances de la version proposée de LLAH.

Pour la première expérience, la méthode proposée a été comparée avec deux autres versions~: le LLAH original et une version avec simplement une réduction de la consommation en mémoire\footnote{Il s'agit en fait de la version proposée pour laquelle seule la réduction en mémoire a été appliquée.}. Pour les trois méthodes et pour chaque critère d'évaluation (mémoire requise, taux de réussite, temps d'exécution et taille moyenne des listes dans la table de hachage\footnote{Les vecteurs de caractéristiques sont munis d'une fonction de hachage pour pouvoir être stockés dans une table de hachage. Si deux vecteurs ont la même valeur de hachage, ils sont stockés derrière la même entrée de la table, dans une liste. Il est important de limiter l'existence de ces listes car elles ralentissent le temps de recherche d'un vecteur de caractéristiques dans la table.}), des mesures ont été effectuées sur des bases de données de 10 000, 100 000, 1 million et 10 millions de pages.

Constats et commentaires\footnote{Remarque personnelle~: il est dommage que les valeurs doivent être lues sur les courbes et qu'elles ne soient pas aussi spécifiées dans un tableau}, critère d'évaluation par critère d'évaluation~:
\begin{description}
	\item[Mémoire requise~:] il n'y a pas vraiment de différences de performance entre la version avec réduction de mémoire seule et la version proposée. Les deux courbes sont quasiment confondues. La seule valeur différente apparaît pour 10 millions de pages. Les deux algorithmes nécessitent respectivement 70 et 77 GB, ce qui ne représente pas une différence relative considérable. En revanche, c'est bien mieux que la version originale qui ne peut tout simplement pas gérer 10 millions de pages et qui requiert 25 GB face à 15 GB pour 1 million de pages. Pour 10 000 et 100 000 pages, les trois méthodes se valent.
	\item[Taux de réussite~:] le taux reste quasiment identique pour toutes les méthodes (entre 99.4\% et 99.6\%) sauf pour 10 millions de pages où la méthode proposée obtient 99.4\% face à 98.6\% pour la méthode avec réduction de mémoire seule. La différence est tout de même peu significative.
	\item[Temps d'exécution~:] la courbe présentée n'a pas vraiment d'intérêt selon moi car les différences ne dépassent jamais 7 ms, ce qui est dérisoire (sauf pour le LLAH original avec 10 millions de pages, qui est impraticable).
	\item[Longueur moyenne des listes~:] on peut faire la même remarque.
\end{description}

A partir de ces résultats, on peut faire le constat général suivant~: Une réduction de mémoire seule est suffisante pour utiliser efficacement LLAH sur des bases de données de 10 millions de pages. En dessous de 1 million de pages, on ne constate pas d'améliorations significatives par rapport à la version originale.

Ces résultats nous amènent à remettre en cause la méthode employée pour améliorer le pouvoir discriminant des vecteurs de caractéristiques. Pour rappel, la dimension de ces vecteurs est $d = ({m\choose 4} + m)$. Il est d'abord dit dans l'article qu'en général $m = 6$, donc $d = 21$. Il est d'abord proposé de fixer $m = 7$, ce qui amène à $d = 42$. Il est ensuite proposé de réduire ce nombre qui pourrait causer beaucoup de faux négatifs. Cependant, ce cas n'est pas testé, ce qui est dommage. Cela aurait permis de vérifier l'hypothèse (ou pourquoi pas d'être agréablement surpris).

Quoi qu'il en soit, la version avec réduction de mémoire présente un taux de réussite très élevé pour 10 millions de pages (98.6\%), que l'on ne peut pas espérer améliorer au-delà de 99.6\%. Chercher à augmenter le pouvoir de discrimination des vecteurs de caractéristiques représente donc "beaucoup d'efforts pour pas grand chose".

Cependant, l'amélioration est plutôt bien réussie compte tenu de la faible marge d'amélioration possible. En effet, après suppression des informations redondantes, la dimension des vecteurs n'est augmentée que de 3, ce qui nous donne une amélioration de 0.8\%, soit 80\% de la marge.

L'expérience 2 montre simplement que la méthode proposée résiste bien aux coupures d'images (fait de proposer seulement une fraction d'image en entrée de l'algorithme). Pour un groupe d'images toutes reconnues sans coupure, 92\% sont toujours bien reconnues même si seulement un huitième de l'image est présenté.

\subsection{Expérimentations du système général}

\subsubsection{Reconnaissance de documents}
Une première expérience a consisté à évaluer les performances du module de reconnaissance des documents dans des conditions réalistes de lecture, en comparant les performances obtenues sur des documents papier et des documents numériques lus sur ordinateur. Cette expérience a le mérite de tester la variation de paramètres liés aux conditions de lecture, ce qui n'est pas fait pour les tests dans l'article dédié à LLAH. Par exemple, des distances caméra-document de 15 cm à 50 cm ont été testées, ainsi que deux noyaux gaussiens de pixellisation de différentes dimensions ($3 \times 3$ et $7 \times 7$). Cela permet de montrer une chute significative du taux de réussite à partir de 35.0 cm ou 45.0 cm de distance selon les cas (voir tableau \ref{tab:results}). Il est important de noter que ces distances ne sont pas des distances de lecture, il n'y a donc aucun problème si les conditions réalistes de lectures ne sont pas respectées pour cette expérience. 

\begin{table}[!h]
\begin{tabular}{c|c|c|c|c|c|c|c|c}
Distance [cm] & 15.0 & 20.0 & 25.0 & 30.0 & 35.0 & 40.0 & 45.0 & 50.0 \\\hline
Efficacité (noyau gaussien $3 \times 3$) [\%] & 99.41 & 100.0 & 100.0 & 100.0 & 100.0 & 98.78 & 74.37 & 23.36 \\\hline
Efficacité (noyau gaussien $7 \times 7$) [\%] & 100.0 & 100.0 & 100.0 & 99.59 & 47.65 & 0.0 & 0.0 & 0.0
\end{tabular}
\caption{\label{tab:results}Taux de réussite de la reconnaissance de documents en fonction de la distance.}
\end{table}

\subsubsection{Choix de la population de test}
Afin d'agrémenter les tests, les auteurs de l'article ont demandé aux utilisateurs leur avis sur l'utilité d'un tel système ainsi que leurs impressions concernant les conditions de lecture. 10 utilisateurs sur 13 ont dit effectivement apprécier d'avoir des informations supplémentaires lors de la lecture d'un document. La première remarque qu'on l'on peut faire afin d'interpréter correctement ce résultat, c'est que le nombre de personnes sondées est trop petit pour pouvoir tirer une conclusion pertinente, ce que reconnaissent d'ailleurs les auteurs. Mais je pense qu'il faut aussi s'interroger sur la manière dont ces personnes ont étés trouvées. La procédure de "recrutement" n'est jamais précisée dans l'article. Or, cela poserait un problème si ces personnes font partie d'une population naturellement disposée à apprécier ce genre de technologies, comme les étudiants en informatique de l'université d'Osaka ou de Kaiserslautern, villes où opèrent les auteurs. Il est évident que les réponses sont biaisées si les personnes proviennent de l'entourage professionnel des chercheurs.

\begin{thebibliography}{1}
	\bibitem{augmented-reality} Augmented Reality, "C'est quoi la Réalité Augmentée ?", [En ligne]. Accessible~: \url{www.augmented-reality.fr/cest-quoi-la-realite-augmentee/}. [Accès le 28 Octobre 2014].
\end{thebibliography}

\newpage

\section{Some \LaTeX{} Examples}
\label{sec:examples}

\subsection{How to Leave Comments}

Comments can be added to the margins of the document using the \todo{Here's a comment in the margin!} todo command, as shown in the example on the right. You can also add inline comments:

\todo[inline, color=green!40]{This is an inline comment.}

\subsection{How to Include Figures}

First you have to upload the image file (JPEG, PNG or PDF) from your computer to writeLaTeX using the upload link the project menu. Then use the includegraphics command to include it in your document. Use the figure environment and the caption command to add a number and a caption to your figure. See the code for Figure \ref{fig:frog} in this section for an example.

%\begin{figure}
%\centering
%\includegraphics[width=0.3\textwidth]{frog.jpg}
%\caption{\label{fig:frog}This frog was uploaded to writeLaTeX via the project menu.}
%\end{figure}

\subsection{How to Make Tables}

Use the table and tabular commands for basic tables --- see Table~\ref{tab:widgets}, for example.

\begin{table}
\centering
\begin{tabular}{l|r}
Item & Quantity \\\hline
Widgets & 42 \\
Gadgets & 13
\end{tabular}
\caption{\label{tab:widgets}An example table.}
\end{table}

\subsection{How to Write Mathematics}

\LaTeX{} is great at typesetting mathematics. Let $X_1, X_2, \ldots, X_n$ be a sequence of independent and identically distributed random variables with $\text{E}[X_i] = \mu$ and $\text{Var}[X_i] = \sigma^2 < \infty$, and let
$$S_n = \frac{X_1 + X_2 + \cdots + X_n}{n}
      = \frac{1}{n}\sum_{i}^{n} X_i$$
denote their mean. Then as $n$ approaches infinity, the random variables $\sqrt{n}(S_n - \mu)$ converge in distribution to a normal $\mathcal{N}(0, \sigma^2)$.

\subsection{How to Make Sections and Subsections}

Use section and subsection commands to organize your document. \LaTeX{} handles all the formatting and numbering automatically. Use ref and label commands for cross-references.

\subsection{How to Make Lists}

You can make lists with automatic numbering \dots

\begin{enumerate}
\item Like this,
\item and like this.
\end{enumerate}
\dots or bullet points \dots
\begin{itemize}
\item Like this,
\item and like this.
\end{itemize}
\dots or with words and descriptions \dots
\begin{description}
\item[Word] Definition
\item[Concept] Explanation
\item[Idea] Text
\end{description}

We hope you find write\LaTeX\ useful, and please let us know if you have any feedback using the help menu above.

\end{document}