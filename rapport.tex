\documentclass[a4paper]{article}

\usepackage[french]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{url}
\usepackage{gensymb}

\title{Rapport ADR : Reconnaissance de documents pour la réalité augmentée}

\author{Gwendal Le Moulec}

\date{\today}

\begin{document}
\maketitle

\begin{abstract}
Ce rapport présente deux articles de recherche. Le premier décrit un système d'affichage d'informations sur un petit écran intégré à des lunettes lors de la lecture d'un document. Le deuxième présente une technique sur laquelle s'appuie le système. Cette technique  permet la reconnaissance d'un document à partir d'une image prise par caméra en la comparant avec celles qui sont stockées dans une base de plus de 10 millions de pages de documents. Nous formulerons des critiques sur les méthodes utilisées, mais surtout sur les résultats obtenus afin de donner notre propre avis sur ces techniques.
\end{abstract}

\section{Introduction}

A l'ère de l'information à grande échelle, la manière de lire de documents n'est plus la même qu'il y a vingt ans. La grande disponibilité des multitudes de sources de données permet à n'importe quel lecteur d'élargir un sujet de lecture, en cherchant lui-même les documents "liés", c'est à dire les documents qui traitent d'au moins une information contenue dans le document initial. Bien souvent, de simples mots-clés couvrent un sujet connexe au sujet principal. Ces mots-clés sont suffisants pour définir un critère de recherche dans une base de données.

Un champ important de recherche en informatique consiste à automatiser ce suivi de liens dans les documents. Les hyperliens que l'on trouve dans les bases de documents comme la fameuse encyclopédie en ligne Wikipédia matérialisent ces connexions de manière simple. Cependant, ce genre d'approche présente quelques faiblesses~: elle ne s'applique qu'au documents numériques et c'est l'auteur du document qui doit définir le lien physique ou au moins préparer le document de manière à ce que la définition du lien soit possible \textit{a posteriori}. Ainsi, un document rédigé dans un format non compatible ne peut définitivement plus être à l'origine de liens.

Cette situation est un peu absurde, puisque ce n'est pas le format du document qui apporte la connaissance, mais bien le contenu du document lui-même. C'est pourquoi on recherche aujourd'hui des méthodes qui permettent d'indexer automatiquement les contenus et bien sûr d'interagir avec des documents indépendamment de leur format, qu'ils soient numériques ou non. Les auteurs des articles présentés dans le présent rapport proposent un mécanisme basé sur la réalité augmentée. La réalité augmentée est un paradigme qui couvre les technologies permettant d'ajouter des données virtuelles dans un monde réel et d'introduire de l'interaction entre les deux \cite{augmented-reality}. Concrètement, le système présenté est constitué de lunettes de réalité augmentée qui permettent d'afficher du contenu virtuel lié au mot fixé par le lecteur. Pour ce faire, le système tente d'abord de reconnaître le document parmi une multitude de références dans une base de données. Ensuite, la reconnaissance d'un mot fixé par le lecteur se fait par mise en relation entre la position du point fixé par le lecteur - détectable grâce à un dispositif de suivi oculaire - et le mot situé à cette position dans la version référencée du document.

Nous présenterons tout d'abord les deux articles proposés afin d'en faire un synthèse. Ils feront ensuite l'objet d'une critique mettant en avant les qualités et les défauts des explications, de la démarche et des résultats présentés.

\section{Présentation des articles}

Les deux articles proposés sont \textit{Wearable Reading Assist System: Augmented Reality Document Combining Document Retrieval and Eye Tracking} (T. Toyama, A. Dengel, W. Suzuki et K. Kise) et \textit{Real-Time Document Image Retrieval for a 10 Million Pages Database with a Memory Efficient and Stability Improved LLAH} (K. Takeda, K. Kise et M. Iwamura). Le premier présente le système général et en particulier la méthode de suivi oculaire, pour la détection des mots fixés successivement par le lecteur. Le deuxième se concentre sur la méthode de reconnaissance de document.

\subsection{Interaction homme-document par suivi oculaire}

Les auteurs du premier article commencent par étudier l'état de l'art de l'interaction sur document par la vision. Il existe des dispositifs adaptés à la lecture sur ordinateur aussi bien que des systèmes portables. Ce sont ces derniers sur lesquelles la méthode proposée se base.

Cette méthode est décomposée en trois modules~:
\begin{description}
	\item[Extraction de document~:] association du document lu avec l'un des documents de la base de données. Le document extrait est appelé image du document.
	\item[Analyse du regard~:] détection des mots-clés fixés successivement.
	\item[Visualisation virtuelle~:] visualisation des données associées au dernier mot-clé fixé.
\end{description}

La figure \ref{fig:system} résume le fonctionnement global du système. L'utilisateur doit porter un dispositif de visualisation composé de lunettes spéciales munies d'un appareil de suivi oculaire sur lesquelles sont montées un petit écran laissant voir le monde réel mais pouvant afficher des données virtuelles. Lorsqu'un document est "présenté" au dispositif, le module d'extraction de documents cherche le document associé. La procédure est expliquée au paragraphe suivant (\ref{subsec:reconnaissance}). Lors de la lecture, l'utilisateur peut fixer des mots. Si ces derniers sont des mots-clés, ils sont stockés dans une pile en attendant que le lecteur porte son regard sur l'écran de réalité augmentée. C'est seulement à ce moment-là que les informations sur le dernier mot-clé fixé sont affichées. En effet, l'affichage de ces données de manière intempestive pourrait gêner l'utilisateur en obstruant son champ de vision.

La détection du regard se fait par projection de rayons infrarouges sur les yeux. Les changements d'angles de réflexion de ces rayons infrarouges permettent de déduire la direction du regard. Ce mécanisme nécessite une calibration pour chaque utilisateur différent.

\begin{figure}[!h]
\centering
\includegraphics[width=\textwidth]{res/systeme_global.png}
\caption{\label{fig:system}Système global.}
\end{figure}

\subsection{Reconnaissance de documents}
\label{subsec:reconnaissance}

Les auteurs du second article proposent une version améliorée d'une technique appelée LLAH (Locally Likely Arrangement Hashing). En effet, cette technique présente deux défauts majeurs~: elle est gourmande en mémoire et son efficacité diminue si la taille de la base de donnée est grande, car il y a plus de chances de rencontrer des documents semblables.

\subsubsection{Fonctionnement de LLAH}
Le fonctionnement de LLAH est le suivant~: au moment du référencement dans la base de données, les points caractéristiques sont extraits. Il s'agit de centroïdes de mots, dont la position varie peu en cas de distorsion. Cette propriété est essentielle pour pouvoir associer efficacement deux documents.

A chaque point caractéristique est associé un vecteur de caractéristiques $V$ tel que~:
\begin{enumerate}
	\item $d = ({m\choose 4} + m)$, où $d$ est la dimension de $V$ et $m$ est un paramètre.
	\item $V = (r_0, ..., r_{{m\choose 4}-1}, q_0, ..., q_{m-1})$, où pour tout $i = 0, ..., {m\choose 4}-1$~:
	
	$r_i = \frac{P(C_{i_1}, C_{i_3}, C_{i_4})}{P(C_{i_1}, C_{i_2}, C_{i_3})}$
	
	Le quadrilatère $C_{i_1}C_{i_2}C_{i_3}C_{i_4}$ étant non-croisé et dont les sommets constituent une combinaison de 4 points parmi les $m$ plus proches voisins du centroïde considéré, lui-même inclus, et $P(A,B,C)$ étant l'aire du triangle $ABC$. Les deux triangles comparés ont donc une arête en commun. Une distorsion provoque une division de l'aire de deux triangles par un même facteur. Le rapport des deux aires est donc invariant par rapport à la distorsion, ce qui explique le choix de cette caractéristique.
\end{enumerate}

\textbf{Remarque personnelle~:} \textit{l'article explique mal la signification des valeurs de $q_0$ à $q_{m-1}$. Il est dit qu'il s'agit des rangs des rapports entre les aires occupées par des mots voisins. La figure \ref{fig:features}, tirée de l'article, montre un exemple pour $m = 6$. Les rapports d'aires semblent triés, mais selon quel critère ? Le tri ne semble pas cohérent avec les rapports apparents. De plus, le sens de comparaison n'est pas spécifié. Pour chaque couple de mot, quelle aire est au numérateur ? Quelle aire est au dénominateur ?}

\begin{figure}[!h]
\centering
\includegraphics[width=0.35\textwidth]{res/features.png}
\caption{\label{fig:features}Calcul du vecteur de caractéristique pour un centroïde.}
\end{figure}

Pour trouver l'image d'un document dans la base de données, on calcule les vecteurs de caractéristiques du document en entrée. L'image correspondante est déterminée par un système de vote~: pour chaque vecteur de caractéristiques, on accorde une voix supplémentaire à tous les documents référencés qui le possèdent également. Le document qui remporte le plus de voix "gagne".

\subsubsection{LLAH amélioré}
La première amélioration proposée est destinée à réduire la consommation en mémoire. Les auteurs proposent de réduire le nombre de points caractéristiques enregistrés car l'algorithme de mise en correspondance, basé sur le vote, n'est pas sensible aux variations du nombre de votants à partir d'un certain seuil. ce seuil est fixé à 200 points caractéristiques au minimum.

Il s'avère aussi que pour des bases de 10 million de pages, les vecteurs de caractéristiques ne sont pas assez discriminants. Pour augmenter le pouvoir de discrimination d'un vecteur, il suffit d'augmenter sa dimension. dans notre cas, une augmentation de la valeur du paramètre $m$ est suffisante. Cependant, augmenter la dimension d'un vecteur augmente aussi le risque d'échec de la comparaison de deux vecteurs qui "devraient être égaux". C'est la raison pour laquelle on supprime également l'information redondante. C'est ainsi que certains attributs de $r_0$ à $r_{{m\choose 4}-1}$ sont éliminés, de façon à ne faire intervenir chaque triangle qu'une seule fois dans tous les calculs.\\
\\

\textbf{Remarque personnelle~:} \textit{Les auteurs justifient ce "filtrage" par le fait qu'étant donnés trois attributs $r_1 = \frac{P_1}{P_2}$, $r_2 = \frac{P_2}{P_3}$ et $r_3 = \frac{P_3}{P_4}$, $r_2$ entretient nécessairement une relation avec $r_1$ et $r_3$. Cependant, cette affirmation n'est pas démontrée rigoureusement. Par exemple, l'un n'est pas une combinaison linéaire des deux autres. Aucun modèle mathématique associé à la distorsion n'est proposé pour démontrer qu'il y a bel et bien redondance d'information.}


\section{Commentaires}

\subsection{Expérimentations de la version améliorée de LLAH}

\subsubsection{Expériences}
Deux expériences ont servi à tester les performances de la version proposée de LLAH.

Pour la première expérience, la méthode proposée a été comparée avec deux autres versions~: le LLAH original et une version avec simplement une réduction de la consommation en mémoire\footnote{Il s'agit en fait de la version proposée pour laquelle seule la réduction en mémoire a été appliquée.}. Pour les trois méthodes et pour chaque critère d'évaluation (mémoire requise, taux de réussite, temps d'exécution et taille moyenne des listes dans la table de hachage\footnote{Les vecteurs de caractéristiques sont munis d'une fonction de hachage pour pouvoir être stockés dans une table de hachage. Si deux vecteurs ont la même valeur de hachage, ils sont stockés derrière la même entrée de la table, dans une liste. Il est important de limiter l'existence de ces listes car elles ralentissent le temps de recherche d'un vecteur de caractéristiques dans la table.}), des mesures ont été effectuées sur des bases de données de 10 000, 100 000, 1 million et 10 millions de pages.

Constats et commentaires\footnote{Remarque personnelle~: il est dommage que les valeurs doivent être lues sur les courbes et qu'elles ne soient pas aussi spécifiées dans un tableau}, critère d'évaluation par critère d'évaluation~:
\begin{description}
	\item[Mémoire requise~:] il n'y a pas vraiment de différences de performance entre la version avec réduction de mémoire seule et la version proposée. Les deux courbes sont quasiment confondues. La seule valeur différente apparaît pour 10 millions de pages. Les deux algorithmes nécessitent respectivement 70 et 77 GB, ce qui ne représente pas une différence relative considérable. En revanche, c'est bien mieux que la version originale qui ne peut tout simplement pas gérer 10 millions de pages et qui requiert 25 GB face à 15 GB pour 1 million de pages. Pour 10 000 et 100 000 pages, les trois méthodes se valent.
	\item[Taux de réussite~:] le taux reste quasiment identique pour toutes les méthodes (entre 99.4\% et 99.6\%) sauf pour 10 millions de pages où la méthode proposée obtient 99.4\% face à 98.6\% pour la méthode avec réduction de mémoire seule. La différence est tout de même peu significative.
	\item[Temps d'exécution~:] la courbe présentée n'a pas vraiment d'intérêt selon moi car les différences ne dépassent jamais 7 ms, ce qui est dérisoire (sauf pour le LLAH original avec 10 millions de pages, qui est impraticable).
	\item[Longueur moyenne des listes~:] on peut faire la même remarque.
\end{description}

A partir de ces résultats, on peut faire le constat général suivant~: Une réduction de mémoire seule est suffisante pour utiliser efficacement LLAH sur des bases de données de 10 millions de pages. En dessous de 1 million de pages, on ne constate pas d'améliorations significatives par rapport à la version originale.

Ces résultats nous amènent à remettre en cause la méthode employée pour améliorer le pouvoir discriminant des vecteurs de caractéristiques. Pour rappel, la dimension de ces vecteurs est $d = ({m\choose 4} + m)$. Il est d'abord dit dans l'article qu'en général $m = 6$, donc $d = 21$. Il est d'abord proposé de fixer $m = 7$, ce qui amène à $d = 42$. Il est ensuite proposé de réduire ce nombre qui pourrait causer beaucoup de faux négatifs. Cependant, ce cas n'est pas testé, ce qui est dommage. Cela aurait permis de vérifier l'hypothèse (ou pourquoi pas d'être agréablement surpris).

Quoi qu'il en soit, la version avec réduction de mémoire présente un taux de réussite très élevé pour 10 millions de pages (98.6\%), que l'on ne peut pas espérer améliorer au-delà de 99.6\%. Chercher à augmenter le pouvoir de discrimination des vecteurs de caractéristiques représente donc "beaucoup d'efforts pour pas grand chose".

Cependant, l'amélioration est plutôt bien réussie compte tenu de la faible marge d'amélioration possible. En effet, après suppression des informations redondantes, la dimension des vecteurs n'est augmentée que de 3, ce qui nous donne une amélioration de 0.8\%, soit 80\% de la marge.

L'expérience 2 montre simplement que la méthode proposée résiste bien aux coupures d'images (fait de proposer seulement une fraction d'image en entrée de l'algorithme). Pour un groupe d'images toutes reconnues sans coupure, 92\% sont toujours bien reconnues même si seulement un huitième de l'image est présenté.

\subsection{Expérimentations du système général}

\subsubsection{Reconnaissance de documents}
Une première expérience a consisté à évaluer les performances du module de reconnaissance des documents dans des conditions réalistes de lecture, en comparant les performances obtenues sur des documents papier et des documents numériques lus sur ordinateur. Cette expérience a le mérite de tester la variation de paramètres liés aux conditions de lecture, ce qui n'est pas fait pour les tests dans l'article dédié à LLAH. Par exemple, des distances caméra-document de 15 cm à 50 cm ont été testées, ainsi que deux noyaux gaussiens de pixellisation de différentes dimensions ($3 \times 3$ et $7 \times 7$). Cela permet de montrer une chute significative du taux de réussite à partir de 35.0 cm ou 45.0 cm de distance selon les cas (voir tableau \ref{tab:results}). Des variations d'angle ont été testées et il est constaté que pour un angle entre la direction du regard et le document compris entre 60\degree et 120\degree, les résultats sont de 100.0\% de réussite. Pour avoir de bonnes performances, il faut que la distance et l'angle soient bons.

\begin{table}[!h]
\begin{tabular}{c|c|c|c|c|c|c|c|c}
Distance [cm] & 15.0 & 20.0 & 25.0 & 30.0 & 35.0 & 40.0 & 45.0 & 50.0 \\\hline
Efficacité (noyau gaussien $3 \times 3$) [\%] & 99.41 & 100.0 & 100.0 & 100.0 & 100.0 & 98.78 & 74.37 & 23.36 \\\hline
Efficacité (noyau gaussien $7 \times 7$) [\%] & 100.0 & 100.0 & 100.0 & 99.59 & 47.65 & 0.0 & 0.0 & 0.0
\end{tabular}
\caption{\label{tab:results}Taux de réussite de la reconnaissance de documents en fonction de la distance.}
\end{table}

L'expérience a été étendue afin de vérifier la faisabilité de la reconnaissance de document dans des conditions réalistes de lecture. Pour cela, 10 personnes ont lu a tour de rôle des documents papier et numériques sur ordinateur comme ils le font dans la vie de tous les jours. Les résultats sont alors extraordinairement élevés. Quasiment dans tous les cas de figure les documents ont été reconnus sans problèmes. Ceci est étonnant car le noyau gaussien utilisé était de dimension $7 \times 7$ pour des distances caméra-document s'étalant de 30.0 cm à 45.0 cm. Suite à la première expérience et dans ces conditions, nous nous serions attendus à une chute significative de la performance au-delà de 35.0 cm.

Cela nous amène à nous interroger sur les conditions dans lesquelles la première expérience a été menée. On peut alors remarquer que même si plusieurs distances et angles sont testés, on ne nous dit pas pour une distance donnée quels angles ont été testés. Les résultats du tableau \ref{tab:results} sont donc finalement difficilement interprétables.

Cependant, la deuxième expérience est plus réaliste, puisqu'elle se focalise sur des conditions réalistes de lecture. Elle semble par conséquent être une meilleure référence pour l'évaluation du système global.

\subsubsection{Reconnaissance de mots-clés et interaction avec l'écran}
Pour ce qui est de la lecture, de la détection des mots-clés fixés et de la navigation sur le HMD, des expériences ont été menées sur 13 personnes dont la tâche était de lire un article de journal. Il était demandé de fixer l'écran à des moments précis, puis de naviguer sur l'interface. Le constat général suivant a été fait~: les utilisateurs pour lesquels la calibration du suiveur de regard s'est mal passée ont obtenu des résultats médiocres (moins de 20\% de réussite pour la reconnaissance de mots-clés, pas d'affichage des informations), alors que les autres ont obtenu de bons résultats.

\subsubsection{Choix de la population de test}
Afin d'agrémenter les tests, les auteurs de l'article ont demandé aux utilisateurs leur avis sur l'utilité d'un tel système. 10 utilisateurs sur 13 ont dit effectivement apprécier d'avoir des informations supplémentaires lors de la lecture d'un document. La première remarque qu'on l'on peut faire afin d'interpréter correctement ce résultat, c'est que le nombre de personnes sondées est trop petit pour pouvoir tirer une conclusion pertinente, ce que reconnaissent d'ailleurs les auteurs. Mais je pense qu'il faut aussi s'interroger sur la manière dont ces personnes ont étés trouvées. La procédure de "recrutement" n'est jamais précisée dans l'article. Or, cela poserait un problème si ces personnes font partie d'une population naturellement disposée à apprécier ce genre de technologies, comme les étudiants en informatique de l'université d'Osaka ou de Kaiserslautern, villes où opèrent les auteurs. Il est évident que les réponses sont biaisées si les personnes proviennent de l'entourage professionnel des chercheurs.

Les mêmes remarques peuvent être faites concernant les expériences elles-mêmes. Il faudrait obtenir des résultats pour les mêmes expériences réalisées sur une population plus importante et plus diversifiée.

Les auteurs ont également demandé aux utilisateurs leur avis sur le confort qu'offre le système. Une partie d'entre eux l'on trouvé encombrant, car il consiste en deux paires de lunettes (le suiveur de regard et le HMD), qui peuvent s'ajouter aux lunettes de vue. De plus, certains ont eu des difficultés avec la calibration. Ainsi, même si le système est techniquement performant, il semble difficilement utilisable en pratique. Selon moi, ceci est un défaut essentiel qu'il faut corriger. Heureusement, cela ne semble pas difficile à faire. En effet, le système physique pourrait être revu et concrétisé en une unique paire de lunettes, adaptées et étudiées pour l'occasion. Il resterait alors le problème de la calibration du suiveur de regard. Les auteurs ont d'ailleurs conclu leur article en disant notamment vouloir y remédier, ce qui est une bonne chose.

\subsection{Reconnaissance d'images}
Même si les résultats sont bons, il faut noter que LLAH n'utilise que les mots et non les images. Les auteurs de l'article reconnaissent d'ailleurs que les pages comportant beaucoup d'images et peu de texte ne sont pas reconnues. L'algorithme gagnerait donc à intégrer une méthode de reconnaissance d'images. Une de ces méthodes, ASIFT (Affine-Self-Invariant Feature Transform) \cite{asift}, se prête bien au contexte d'utilisation du système global, car elle a l'avantage d'être adaptée à la reconnaissance d'images soumises à des distorsions, des rotations ou du zoom. De plus, la manière de l'utiliser est similaire à la reconnaissance de documents telle que décrite dans l'article~: une première photographie de l'image prise dans de bonnes conditions doit-être stockée dans la base. C'est ce qui est naturellement fait lors de l'enregistrement des photographies de documents. Il est alors possible de comparer les vecteurs de caractéristiques des images enregistrées et d'une image "lue" déformée. Le système de vote peut être utilisé pour ce cas de figure. 

Enfin, il est possible d'utiliser les images comme les mots-clés, pour affichage d'information complémentaires sur le HMD. C'est ce que montre la méthode exposée dans \cite{annotation}, qui permet d'annoter une image par quelques mots-clés la décrivant de manière pertinente. Parmi ce mots-clés, ceux qui sont aussi des mots-clés du document en question permettraient à l'image de donner lieu à l'affichage des informations complémentaires correspondantes, après détection de la fixation de l'image par le lecteur.

\section{Conclusion}
Nous avons étudié un article présentant une technique permettant d'obtenir des informations complémentaires lors de la lecture d'un document. Le lecteur porte des lunettes qui suivent la position du regard et affichent des informations liées à un mot-clé sur un petit écran intégré aux lunettes. L'utilisateur a alors accès à une interface avec des boutons sur laquelle il peut naviguer simplement avec le regard. La technique repose en partie sur la reconnaissance du document lu, dont une image est trouvée dans une base de données. Le deuxième article étudié explique le fonctionnement d'un algorithme dédié à cette tâche, LLAH. Dans ce même article, une amélioration est proposée. Celle-ci permet de diminuer la consommation en mémoire et d'augmenter le taux de réussite. Il permet ainsi de gérer une base de plus de 10 millions de pages, alors que la version originale de LLAH ne permet pas de gérer plus de 1 million de pages.

Quelques critiques ont été émises sur ces articles ; sur la démarche présentée mais surtout sur les expériences de validation et l'interprétation de leurs résultats. Nous avons alors mis en évidence le fait que le système global de lecture devrait être testé sur une population plus grande et dont la diversité devait être au moins connue. Nous avons aussi souligné la difficulté d'utilisation du système en pratique. Pour ce qui est de la version améliorée de LLAH, nous avons montré qu'une simple réduction du nombre de points caractéristiques utilisés pour reconnaître l'image du document était suffisante pour rendre l'algorithme efficace et utilisable sur des bases de données de 10 millions de pages. La raison n'en est pas que l'augmentation du pouvoir discriminant des vecteurs de caractéristiques n'augmente pas le taux de réussite, mais plutôt que la marge d'augmentation est très faible (1\% seulement).

Il existe des solutions qui affranchissent de la lourdeur du système. Par exemple, HotPaper \cite{hotpaper} est un système de reconnaissance de documents pour téléphones que les auteurs citent eux-mêmes. Une idée pourrait-être de porter une solution utilisant LLAH ou sa version améliorée sur téléphone. Notez bien que lorsque l'article \cite{hotpaper} a été écrit, les téléphones portables étaient dotés de caméras de bien moins bonne qualité que celles des smartphones d'aujourd'hui\footnote{La résolution de la caméra de test de HotPaper est de $177 \times 144$ pixels alors que la résolution du Samsung Galaxy S5 par exemple, est de 16MP}. Il est vrai que l'on perd l'interaction uniquement par le regard, mais il n'y a plus besoin de calibration "stressante" et les utilisateurs sont en général habitués à manipuler un smartphone.

\begin{thebibliography}{1}
	\bibitem{augmented-reality} Augmented Reality, "C'est quoi la Réalité Augmentée ?", [En ligne]. Accessible~: \url{www.augmented-reality.fr/cest-quoi-la-realite-augmentee/}. [Accès le 28 Octobre 2014].
	\bibitem{asift} YU, Guoshen et MOREL, J.-M. A fully affine invariant image comparison method. In : Acoustics, Speech and Signal Processing, 2009. ICASSP 2009. IEEE International Conference on. IEEE, 2009. p. 1597-1600.
	\bibitem{annotation} J. Jeon, V. Lavrenko et R. Manmatha, "Automatic Image Annotation and Retrieval using Cross-Media Relevance Models", dans \textit{Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval}, 2003, pp.119-126.
	\bibitem{hotpaper} B. Erol, E. Ant\'unez et J. J. Hull, "Hotpaper: multimedia interaction with paper using mobile phones", dans \textit{Proceedings of the 16th ACM international conference on Multimedia}, 2008, pp.399-408.
\end{thebibliography}

\end{document}